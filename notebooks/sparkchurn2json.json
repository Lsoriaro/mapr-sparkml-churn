{"paragraphs":[{"title":"Import needed packages","text":"import org.apache.spark._\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\nimport org.apache.spark.ml.classification.DecisionTreeClassificationModel\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.tuning.ParamGridBuilder\nimport org.apache.spark.ml.tuning.CrossValidator\nimport org.apache.spark.ml.feature.VectorAssembler","user":"anonymous","dateUpdated":"2017-06-03T17:54:19-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark._\n\nimport org.apache.spark.sql.SparkSession\n\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.sql.types._\n\nimport org.apache.spark.sql._\n\nimport org.apache.spark.sql.Dataset\n\nimport org.apache.spark.ml.Pipeline\n\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\n\nimport org.apache.spark.ml.classification.DecisionTreeClassificationModel\n\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n\nimport org.apache.spark.ml.feature.StringIndexer\n\nimport org.apache.spark.ml.tuning.ParamGridBuilder\n\nimport org.apache.spark.ml.tuning.CrossValidator\n\nimport org.apache.spark.ml.feature.VectorAssembler\n"}]},"apps":[],"jobName":"paragraph_1494279914993_614378577","id":"20170508-144514_403247535","dateCreated":"2017-05-08T14:45:14-0700","dateStarted":"2017-06-03T17:54:19-0700","dateFinished":"2017-06-03T17:54:31-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:13978"},{"text":"%md \nFor this tutorial, we'll be using the Orange Telecoms Churn Dataset. It consists of cleaned customer activity data (features), along with a churn label specifying whether the customer canceled their subscription or not. The input  csv file has the following format: \nKS,128,415,No,Yes,25,265.1,110,45.07,197.4,99,16.78,244.7,91,11.01,10.0,3,2.7,1,False\n\nWe use a Scala case class and Structype to define the schema, corresponding to a line in the csv data file.","user":"anonymous","dateUpdated":"2017-06-01T15:38:38-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>For this tutorial, we&rsquo;ll be using the Orange Telecoms Churn Dataset. It consists of cleaned customer activity data (features), along with a churn label specifying whether the customer canceled their subscription or not. The input csv file has the following format:<br/>KS,128,415,No,Yes,25,265.1,110,45.07,197.4,99,16.78,244.7,91,11.01,10.0,3,2.7,1,False</p>\n<p>We use a Scala case class and Structype to define the schema, corresponding to a line in the csv data file.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1496172585029_1989731503","id":"20170530-122945_1594214131","dateCreated":"2017-05-30T12:29:45-0700","dateStarted":"2017-06-01T15:38:38-0700","dateFinished":"2017-06-01T15:38:38-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13979"},{"text":"","user":"anonymous","dateUpdated":"2017-06-02T15:57:13-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":"org.apache.zeppelin.interpreter.InterpreterException: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused","apps":[],"jobName":"paragraph_1495581090290_-1042376002","id":"20170523-161130_2119104935","dateCreated":"2017-05-23T16:11:30-0700","dateStarted":"2017-05-24T19:58:12-0700","dateFinished":"2017-05-24T19:58:42-0700","status":"FINISHED","errorMessage":"java.net.ConnectException: Connection refused\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:589)\n\tat org.apache.thrift.transport.TSocket.open(TSocket.java:182)\n\tat org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:51)\n\tat org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:37)\n\tat org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:60)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:861)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:435)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.getClient(RemoteInterpreterProcess.java:90)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.init(RemoteInterpreter.java:209)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getFormType(RemoteInterpreter.java:375)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.getFormType(LazyOpenInterpreter.java:105)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:365)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:329)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","progressUpdateIntervalMs":500,"$$hashKey":"object:13980"},{"title":"Define Schema for csv file data","text":"  case class Account(state: String, len: Integer, acode: String,\n    intlplan: String, vplan: String, numvmail: Double,\n    tdmins: Double, tdcalls: Double, tdcharge: Double,\n    temins: Double, tecalls: Double, techarge: Double,\n    tnmins: Double, tncalls: Double, tncharge: Double,\n    timins: Double, ticalls: Double, ticharge: Double,\n    numcs: Double, churn: String)\n  val schema = StructType(Array(\n    StructField(\"state\", StringType, true),\n    StructField(\"len\", IntegerType, true),\n    StructField(\"acode\", StringType, true),\n    StructField(\"intlplan\", StringType, true),\n    StructField(\"vplan\", StringType, true),\n    StructField(\"numvmail\", DoubleType, true),\n    StructField(\"tdmins\", DoubleType, true),\n    StructField(\"tdcalls\", DoubleType, true),\n    StructField(\"tdcharge\", DoubleType, true),\n    StructField(\"temins\", DoubleType, true),\n    StructField(\"tecalls\", DoubleType, true),\n    StructField(\"techarge\", DoubleType, true),\n    StructField(\"tnmins\", DoubleType, true),\n    StructField(\"tncalls\", DoubleType, true),\n    StructField(\"tncharge\", DoubleType, true),\n    StructField(\"timins\", DoubleType, true),\n    StructField(\"ticalls\", DoubleType, true),\n    StructField(\"ticharge\", DoubleType, true),\n    StructField(\"numcs\", DoubleType, true),\n    StructField(\"churn\", StringType, true)\n  ))","user":"anonymous","dateUpdated":"2017-06-03T18:18:23-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndefined class Account\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(state,StringType,true), StructField(len,IntegerType,true), StructField(acode,StringType,true), StructField(intlplan,StringType,true), StructField(vplan,StringType,true), StructField(numvmail,DoubleType,true), StructField(tdmins,DoubleType,true), StructField(tdcalls,DoubleType,true), StructField(tdcharge,DoubleType,true), StructField(temins,DoubleType,true), StructField(tecalls,DoubleType,true), StructField(techarge,DoubleType,true), StructField(tnmins,DoubleType,true), StructField(tncalls,DoubleType,true), StructField(tncharge,DoubleType,true), StructField(timins,DoubleType,true), StructField(ticalls,DoubleType,true), StructField(ticharge,DoubleType,true), StructField(numcs,DoubleType,true), StructField(churn,StringT..."}]},"apps":[],"jobName":"paragraph_1494280832510_1432252402","id":"20170508-150032_326029627","dateCreated":"2017-05-08T15:00:32-0700","dateStarted":"2017-06-03T18:18:23-0700","dateFinished":"2017-06-03T18:18:25-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13981"},{"title":"Read the data from CSV file into a Dataset of Account type","text":"import spark.implicits._\nval train: Dataset[Account] = spark.read.option(\"inferSchema\", \"false\")\n      .schema(schema).csv(\"/user/user01/data/churn-bigml-80.csv\").as[Account]\ntrain.count()  \ntrain.cache()\ntrain.first()","user":"anonymous","dateUpdated":"2017-06-03T18:18:40-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport spark.implicits._\n\ntrain: org.apache.spark.sql.Dataset[Account] = [state: string, len: int ... 18 more fields]\n\nres53: Long = 2666\n\nres54: train.type = [state: string, len: int ... 18 more fields]\n\nres55: Account = Account(KS,128,415,No,Yes,25.0,265.1,110.0,45.07,197.4,99.0,16.78,244.7,91.0,11.01,10.0,3.0,2.7,1.0,False)\n"}]},"apps":[],"jobName":"paragraph_1494280891041_1752440108","id":"20170508-150131_378637203","dateCreated":"2017-05-08T15:01:31-0700","dateStarted":"2017-06-03T18:18:40-0700","dateFinished":"2017-06-03T18:18:49-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13982"},{"text":"val test: Dataset[Account] = spark.read.option(\"inferSchema\", \"false\")\n      .schema(schema).csv(\"/user/user01/data/churn-bigml-20.csv\").as[Account]\ntest.count()      \ntest.first()\n    ","user":"anonymous","dateUpdated":"2017-06-03T18:18:58-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ntest: org.apache.spark.sql.Dataset[Account] = [state: string, len: int ... 18 more fields]\n\nres56: Long = 667\n\nres57: Account = Account(LA,117,408,No,No,0.0,184.5,97.0,31.37,351.6,80.0,29.89,215.8,90.0,9.71,8.7,4.0,2.35,1.0,False)\n"}]},"apps":[],"jobName":"paragraph_1494281004434_1784559802","id":"20170508-150324_497571301","dateCreated":"2017-05-08T15:03:24-0700","dateStarted":"2017-06-03T18:18:58-0700","dateFinished":"2017-06-03T18:19:02-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13983"},{"title":"Register Dataset as a Table , display first 20 rows ","text":"train.createOrReplaceTempView(\"account\")\nspark.catalog.cacheTable(\"account\")\ntrain.show","user":"anonymous","dateUpdated":"2017-06-03T18:24:06-0700","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":true,"setting":{"stackedAreaChart":{}},"commonSetting":{},"keys":[{"name":"churn","index":19,"aggr":"sum"}],"groups":[],"values":[{"name":"len","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+---+-----+--------+-----+--------+------+-------+--------+------+-------+--------+------+-------+--------+------+-------+--------+-----+-----+\n|state|len|acode|intlplan|vplan|numvmail|tdmins|tdcalls|tdcharge|temins|tecalls|techarge|tnmins|tncalls|tncharge|timins|ticalls|ticharge|numcs|churn|\n+-----+---+-----+--------+-----+--------+------+-------+--------+------+-------+--------+------+-------+--------+------+-------+--------+-----+-----+\n|   KS|128|  415|      No|  Yes|    25.0| 265.1|  110.0|   45.07| 197.4|   99.0|   16.78| 244.7|   91.0|   11.01|  10.0|    3.0|     2.7|  1.0|False|\n|   OH|107|  415|      No|  Yes|    26.0| 161.6|  123.0|   27.47| 195.5|  103.0|   16.62| 254.4|  103.0|   11.45|  13.7|    3.0|     3.7|  1.0|False|\n|   NJ|137|  415|      No|   No|     0.0| 243.4|  114.0|   41.38| 121.2|  110.0|    10.3| 162.6|  104.0|    7.32|  12.2|    5.0|    3.29|  0.0|False|\n|   OH| 84|  408|     Yes|   No|     0.0| 299.4|   71.0|    50.9|  61.9|   88.0|    5.26| 196.9|   89.0|    8.86|   6.6|    7.0|    1.78|  2.0|False|\n|   OK| 75|  415|     Yes|   No|     0.0| 166.7|  113.0|   28.34| 148.3|  122.0|   12.61| 186.9|  121.0|    8.41|  10.1|    3.0|    2.73|  3.0|False|\n|   AL|118|  510|     Yes|   No|     0.0| 223.4|   98.0|   37.98| 220.6|  101.0|   18.75| 203.9|  118.0|    9.18|   6.3|    6.0|     1.7|  0.0|False|\n|   MA|121|  510|      No|  Yes|    24.0| 218.2|   88.0|   37.09| 348.5|  108.0|   29.62| 212.6|  118.0|    9.57|   7.5|    7.0|    2.03|  3.0|False|\n|   MO|147|  415|     Yes|   No|     0.0| 157.0|   79.0|   26.69| 103.1|   94.0|    8.76| 211.8|   96.0|    9.53|   7.1|    6.0|    1.92|  0.0|False|\n|   WV|141|  415|     Yes|  Yes|    37.0| 258.6|   84.0|   43.96| 222.0|  111.0|   18.87| 326.4|   97.0|   14.69|  11.2|    5.0|    3.02|  0.0|False|\n|   RI| 74|  415|      No|   No|     0.0| 187.7|  127.0|   31.91| 163.4|  148.0|   13.89| 196.0|   94.0|    8.82|   9.1|    5.0|    2.46|  0.0|False|\n|   IA|168|  408|      No|   No|     0.0| 128.8|   96.0|    21.9| 104.9|   71.0|    8.92| 141.1|  128.0|    6.35|  11.2|    2.0|    3.02|  1.0|False|\n|   MT| 95|  510|      No|   No|     0.0| 156.6|   88.0|   26.62| 247.6|   75.0|   21.05| 192.3|  115.0|    8.65|  12.3|    5.0|    3.32|  3.0|False|\n|   IA| 62|  415|      No|   No|     0.0| 120.7|   70.0|   20.52| 307.2|   76.0|   26.11| 203.0|   99.0|    9.14|  13.1|    6.0|    3.54|  4.0|False|\n|   ID| 85|  408|      No|  Yes|    27.0| 196.4|  139.0|   33.39| 280.9|   90.0|   23.88|  89.3|   75.0|    4.02|  13.8|    4.0|    3.73|  1.0|False|\n|   VT| 93|  510|      No|   No|     0.0| 190.7|  114.0|   32.42| 218.2|  111.0|   18.55| 129.6|  121.0|    5.83|   8.1|    3.0|    2.19|  3.0|False|\n|   VA| 76|  510|      No|  Yes|    33.0| 189.7|   66.0|   32.25| 212.8|   65.0|   18.09| 165.7|  108.0|    7.46|  10.0|    5.0|     2.7|  1.0|False|\n|   TX| 73|  415|      No|   No|     0.0| 224.4|   90.0|   38.15| 159.5|   88.0|   13.56| 192.8|   74.0|    8.68|  13.0|    2.0|    3.51|  1.0|False|\n|   FL|147|  415|      No|   No|     0.0| 155.1|  117.0|   26.37| 239.7|   93.0|   20.37| 208.8|  133.0|     9.4|  10.6|    4.0|    2.86|  0.0|False|\n|   CO| 77|  408|      No|   No|     0.0|  62.4|   89.0|   10.61| 169.9|  121.0|   14.44| 209.6|   64.0|    9.43|   5.7|    6.0|    1.54|  5.0| True|\n|   AZ|130|  415|      No|   No|     0.0| 183.0|  112.0|   31.11|  72.9|   99.0|     6.2| 181.8|   78.0|    8.18|   9.5|   19.0|    2.57|  0.0|False|\n+-----+---+-----+--------+-----+--------+------+-------+--------+------+-------+--------+------+-------+--------+------+-------+--------+-----+-----+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1494281048853_-478671146","id":"20170508-150408_505244914","dateCreated":"2017-05-08T15:04:08-0700","dateStarted":"2017-06-03T18:19:08-0700","dateFinished":"2017-06-03T18:19:10-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13984"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1495687600319_1622017323","id":"20170524-214640_973339640","dateCreated":"2017-05-24T21:46:40-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13985","text":"%md\nThe describe() function performs summary statistics calculations on  numeric columns ","dateUpdated":"2017-06-03T18:20:17-0700","dateFinished":"2017-06-03T18:20:17-0700","dateStarted":"2017-06-03T18:20:17-0700","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>The describe() function performs summary statistics calculations on numeric columns</p>\n</div>"}]}},{"title":"Perform summary statistics  on selected columns","text":"\ntrain.describe(\"tdcharge\", \"techarge\",\"tncharge\", \"numcs\").show","user":"anonymous","dateUpdated":"2017-06-03T18:24:51-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------------------+------------------+------------------+------------------+\n|summary|          tdcharge|          techarge|          tncharge|             numcs|\n+-------+------------------+------------------+------------------+------------------+\n|  count|              2666|              2666|              2666|              2666|\n|   mean|30.512404351087813|17.033072018004518| 9.052689422355604|1.5626406601650413|\n| stddev| 9.215732907163497| 4.330864176799864|2.2851195129157564|1.3112357589949093|\n|    min|               0.0|               0.0|              1.97|               0.0|\n|    max|             59.64|             30.91|             17.77|               9.0|\n+-------+------------------+------------------+------------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1495639948382_-1348242623","id":"20170524-083228_1459810795","dateCreated":"2017-05-24T08:32:28-0700","dateStarted":"2017-06-03T18:24:51-0700","dateFinished":"2017-06-03T18:24:53-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13986"},{"title":"Calculate the correlation between Total day minutes and Total day charge","text":"import org.apache.spark.mllib.stat.Statistics\nval tdmins = train.select(\"tdmins\").map{row:Row => row.getAs[Double](\"tdmins\")}.rdd\nval tdcharge = train.select( \"tdcharge\").map{row:Row => row.getAs[Double](\"tdcharge\")}.rdd\nval correlation = Statistics.corr(tdmins, tdcharge, \"pearson\")","user":"anonymous","dateUpdated":"2017-06-03T18:25:50-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.mllib.stat.Statistics\n\ntdmins: org.apache.spark.rdd.RDD[Double] = MapPartitionsRDD[1362] at rdd at <console>:156\n\ntdcharge: org.apache.spark.rdd.RDD[Double] = MapPartitionsRDD[1365] at rdd at <console>:156\n\ncorrelation: Double = 0.9999999517969665\n"}]},"apps":[],"jobName":"paragraph_1495643512861_-320890325","id":"20170524-093152_48310549","dateCreated":"2017-05-24T09:31:52-0700","dateStarted":"2017-06-03T18:25:50-0700","dateFinished":"2017-06-03T18:25:56-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13987"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1496539615621_611940282","id":"20170603-182655_1680505289","dateCreated":"2017-06-03T18:26:55-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15669","text":"%md \nuse Spark SQL to explore the dataset","dateUpdated":"2017-06-03T18:27:24-0700","dateFinished":"2017-06-03T18:27:24-0700","dateStarted":"2017-06-03T18:27:24-0700","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>use Spark SQL to explore the dataset</p>\n</div>"}]}},{"title":"Count number customers grouped by churn","text":"train.groupBy(\"churn\").count.show\n","user":"anonymous","dateUpdated":"2017-06-03T18:25:58-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+-----+\n|churn|count|\n+-----+-----+\n|False| 2278|\n| True|  388|\n+-----+-----+\n\n"}]},"apps":[],"jobName":"paragraph_1495643642846_-282614649","id":"20170524-093402_1430077788","dateCreated":"2017-05-24T09:34:02-0700","dateStarted":"2017-06-03T18:25:58-0700","dateFinished":"2017-06-03T18:26:00-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13988"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1496540258198_-1714376927","id":"20170603-183738_564410056","dateCreated":"2017-06-03T18:37:38-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:17447","text":"val fractions = Map(\"False\" -> .17, \"True\" -> 1.0)\n//Here we're keeping all instances of the Churn=True class, but downsampling the Churn=False class to a fraction of 388/2278.\nval strain = train.stat.sampleBy(\"churn\", fractions, 36L)\n\nstrain.groupBy(\"churn\").count.show\nstrain.createOrReplaceTempView(\"account\")\nspark.catalog.cacheTable(\"account\")","dateUpdated":"2017-06-03T18:39:58-0700","dateFinished":"2017-06-03T18:40:04-0700","dateStarted":"2017-06-03T18:39:58-0700","title":"Use sampleBy to reduce number of churn=false samples ","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nfractions: scala.collection.immutable.Map[String,Double] = Map(False -> 0.17, True -> 1.0)\n\nstrain: org.apache.spark.sql.DataFrame = [state: string, len: int ... 18 more fields]\n+-----+-----+\n|churn|count|\n+-----+-----+\n|False|  379|\n| True|  388|\n+-----+-----+\n\n"}]}},{"title":"Explore Average statistics grouped by churn","text":"z.show(strain.groupBy(\"churn\").avg())","user":"anonymous","dateUpdated":"2017-06-03T18:40:51-0700","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"churn","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"avg(tdmins)","index":3,"aggr":"sum"},{"name":"avg(temins)","index":6,"aggr":"sum"},{"name":"avg(tnmins)","index":9,"aggr":"sum"},{"name":"avg(timins)","index":12,"aggr":"sum"},{"name":"avg(len)","index":1,"aggr":"sum"},{"name":"avg(numcs)","index":15,"aggr":"sum"},{"name":"avg(tdcalls)","index":4,"aggr":"sum"},{"name":"avg(tecalls)","index":7,"aggr":"sum"},{"name":"avg(ticalls)","index":13,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"churn\tavg(len)\tavg(numvmail)\tavg(tdmins)\tavg(tdcalls)\tavg(tdcharge)\tavg(temins)\tavg(tecalls)\tavg(techarge)\tavg(tnmins)\tavg(tncalls)\tavg(tncharge)\tavg(timins)\tavg(ticalls)\tavg(ticharge)\tavg(numcs)\nFalse\t96.47757255936675\t8.168865435356201\t174.07730870712402\t99.45646437994723\t29.593588390501342\t200.14063324538245\t99.10554089709763\t17.01216358839051\t202.1079155672821\t98.79683377308707\t9.09472295514512\t10.081266490765167\t4.430079155672823\t2.7224538258575177\t1.3852242744063326\nTrue\t102.31958762886597\t5.170103092783505\t205.1811855670104\t101.19587628865979\t34.88134020618558\t209.38530927835052\t99.94845360824742\t17.79786082474226\t205.30721649484514\t100.68298969072166\t9.23889175257732\t10.81932989690722\t4.051546391752577\t2.9217268041237117\t2.2061855670103094\n"}]},"apps":[],"jobName":"paragraph_1495646407540_-1562725146","id":"20170524-102007_926152177","dateCreated":"2017-05-24T10:20:07-0700","dateStarted":"2017-06-03T18:40:51-0700","dateFinished":"2017-06-03T18:40:54-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13989"},{"title":"Explore average number customer service calls grouped by churn","text":"%sql\nSELECT churn, avg(numcs) as numcs\nFROM account \nGROUP BY churn\nORDER BY numcs","user":"anonymous","dateUpdated":"2017-06-03T18:41:12-0700","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"pieChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"churn","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"numcs","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"churn\tnumcs\nFalse\t1.3852242744063326\nTrue\t2.2061855670103094\n"}]},"apps":[],"jobName":"paragraph_1495644687361_1825153673","id":"20170524-095127_757444423","dateCreated":"2017-05-24T09:51:27-0700","dateStarted":"2017-06-03T18:41:12-0700","dateFinished":"2017-06-03T18:41:14-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13990"},{"title":"Explore Average statistics grouped by churn","text":"%sql\nSELECT churn, \n  avg(tdmins) as td,\n  avg(temins) as te,\n  avg(tnmins) as tn\nFROM account \nGROUP BY churn\n","user":"anonymous","dateUpdated":"2017-06-03T18:43:37-0700","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false}},"commonSetting":{},"keys":[{"name":"churn","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"td","index":1,"aggr":"avg"},{"name":"te","index":2,"aggr":"avg"},{"name":"tn","index":3,"aggr":"avg"}]},"helium":{}}},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"churn\ttd\tte\ttn\nFalse\t174.07730870712402\t200.14063324538245\t202.1079155672821\nTrue\t205.1811855670104\t209.38530927835052\t205.30721649484514\n"}]},"apps":[],"jobName":"paragraph_1495662471522_-1606952051","id":"20170524-144751_554129160","dateCreated":"2017-05-24T14:47:51-0700","dateStarted":"2017-06-03T18:42:50-0700","dateFinished":"2017-06-03T18:42:52-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13991"},{"title":"Drop columns that we will not use for machine learning ","text":"val ntrain = strain.drop(\"state\").drop(\"acode\").drop(\"vplan\").drop(\"tdcharge\").drop(\"techarge\").drop(\"ticharge\")\nprintln(ntrain.count)\nntrain.show","user":"anonymous","dateUpdated":"2017-06-03T18:46:55-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nntrain: org.apache.spark.sql.DataFrame = [len: int, intlplan: string ... 12 more fields]\n767\n+---+--------+--------+------+-------+------+-------+------+-------+--------+------+-------+-----+-----+\n|len|intlplan|numvmail|tdmins|tdcalls|temins|tecalls|tnmins|tncalls|tncharge|timins|ticalls|numcs|churn|\n+---+--------+--------+------+-------+------+-------+------+-------+--------+------+-------+-----+-----+\n|128|      No|    25.0| 265.1|  110.0| 197.4|   99.0| 244.7|   91.0|   11.01|  10.0|    3.0|  1.0|False|\n| 77|      No|     0.0|  62.4|   89.0| 169.9|  121.0| 209.6|   64.0|    9.43|   5.7|    6.0|  5.0| True|\n| 54|      No|     0.0| 134.3|   73.0| 155.5|  100.0| 102.1|   68.0|    4.59|  14.7|    4.0|  3.0|False|\n| 12|      No|     0.0| 249.6|  118.0| 252.4|  119.0| 280.2|   90.0|   12.61|  11.8|    3.0|  1.0| True|\n| 57|      No|    25.0| 176.8|   94.0| 195.0|   75.0| 213.5|  116.0|    9.61|   8.3|    4.0|  0.0|False|\n|135|     Yes|    41.0| 173.1|   85.0| 203.9|  107.0| 122.2|   78.0|     5.5|  14.6|   15.0|  0.0| True|\n|160|      No|     0.0|  85.8|   77.0| 165.3|  110.0| 178.5|   92.0|    8.03|   9.2|    4.0|  3.0|False|\n| 96|      No|     0.0| 160.2|  117.0| 267.5|   67.0| 228.5|   68.0|   10.28|   9.3|    5.0|  2.0|False|\n| 87|      No|     0.0| 151.0|   83.0| 219.7|  116.0| 203.9|  127.0|    9.18|   9.7|    3.0|  5.0| True|\n|121|      No|    30.0| 198.4|  129.0|  75.3|   77.0| 181.2|   77.0|    8.15|   5.8|    3.0|  3.0| True|\n| 38|      No|     0.0| 131.2|   98.0| 162.9|   97.0| 159.0|  106.0|    7.15|   8.2|    6.0|  2.0|False|\n|150|      No|     0.0| 178.9|  101.0| 169.1|  110.0| 148.6|  100.0|    6.69|  13.8|    3.0|  4.0| True|\n|147|      No|     0.0| 248.6|   83.0| 148.9|   85.0| 172.5|  109.0|    7.76|   8.0|    4.0|  3.0|False|\n| 82|      No|     0.0| 300.3|  109.0| 181.0|  100.0| 270.1|   73.0|   12.15|  11.7|    4.0|  0.0| True|\n|144|      No|     0.0|  61.6|  117.0|  77.1|   85.0| 173.0|   99.0|    7.79|   8.2|    7.0|  4.0| True|\n| 70|      No|     0.0| 170.2|   98.0| 155.2|  102.0| 228.6|   76.0|   10.29|  15.0|    2.0|  1.0|False|\n|106|      No|     0.0| 210.6|   96.0| 249.2|   85.0| 191.4|   88.0|    8.61|  12.4|    1.0|  2.0| True|\n| 94|      No|     0.0| 157.9|  105.0| 155.0|  101.0| 189.6|   84.0|    8.53|   8.0|    5.0|  4.0| True|\n|128|      No|     0.0| 237.9|  125.0| 247.6|   93.0| 208.9|   68.0|     9.4|  13.9|    4.0|  1.0| True|\n| 82|      No|     0.0| 143.9|   61.0| 194.9|  105.0| 109.6|   94.0|    4.93|  11.1|    2.0|  1.0|False|\n+---+--------+--------+------+-------+------+-------+------+-------+--------+------+-------+-----+-----+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1495689059850_1020265339","id":"20170524-221059_1333485772","dateCreated":"2017-05-24T22:10:59-0700","dateStarted":"2017-06-03T18:46:55-0700","dateFinished":"2017-06-03T18:46:57-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13993"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1496540891851_-874534663","id":"20170603-184811_78732818","dateCreated":"2017-06-03T18:48:11-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18797","text":"%md\nIn order for the features to be used by a machine learning algorithm, they are transformed into numbers representing the value for each feature\n","dateUpdated":"2017-06-03T18:49:17-0700","dateFinished":"2017-06-03T18:49:17-0700","dateStarted":"2017-06-03T18:49:17-0700","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In order for the features to be used by a machine learning algorithm, they are transformed into numbers representing the value for each feature</p>\n</div>"}]}},{"title":"Map International Plan Yes No to Numbers","text":"val ipindexer = new StringIndexer()\n      .setInputCol(\"intlplan\")\n      .setOutputCol(\"iplanIndex\")\n\n","user":"anonymous","dateUpdated":"2017-06-03T18:51:08-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nipindexer: org.apache.spark.ml.feature.StringIndexer = strIdx_e80eda16cd5f\n"}]},"apps":[],"jobName":"paragraph_1494281143985_1653142599","id":"20170508-150543_958647761","dateCreated":"2017-05-08T15:05:43-0700","dateStarted":"2017-06-03T18:51:08-0700","dateFinished":"2017-06-03T18:51:09-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13994"},{"title":"Map churn true false to  Numbers","text":"val labelindexer = new StringIndexer()\n      .setInputCol(\"churn\")\n      .setOutputCol(\"label\")\n","user":"anonymous","dateUpdated":"2017-06-03T18:51:12-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nlabelindexer: org.apache.spark.ml.feature.StringIndexer = strIdx_9b8047ade281\n"}]},"apps":[],"jobName":"paragraph_1495689695991_1833326777","id":"20170524-222135_122500289","dateCreated":"2017-05-24T22:21:35-0700","dateStarted":"2017-06-03T18:51:12-0700","dateFinished":"2017-06-03T18:51:12-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13995"},{"title":"Use VectorAssembler, a transformer,  to put features into a feature vector column","text":"val featureCols = Array(\"len\", \"iplanIndex\", \"numvmail\", \"tdmins\", \"tdcalls\", \"temins\", \"tecalls\", \"tnmins\", \"tncalls\", \"timins\", \"ticalls\", \"numcs\")\nval assembler = new VectorAssembler()\n      .setInputCols(featureCols)\n      .setOutputCol(\"features\")\n","user":"anonymous","dateUpdated":"2017-06-03T18:51:17-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nfeatureCols: Array[String] = Array(len, iplanIndex, numvmail, tdmins, tdcalls, temins, tecalls, tnmins, tncalls, timins, ticalls, numcs)\n\nassembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_60c25e2d6ceb\n"}]},"apps":[],"jobName":"paragraph_1495690390299_42497435","id":"20170524-223310_2121058884","dateCreated":"2017-05-24T22:33:10-0700","dateStarted":"2017-06-03T18:51:18-0700","dateFinished":"2017-06-03T18:51:19-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13996"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1496541285652_119455636","id":"20170603-185445_276463997","dateCreated":"2017-06-03T18:54:45-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19034","text":"val dTree = new DecisionTreeClassifier().setLabelCol(\"label\")\n      .setFeaturesCol(\"features\")","dateUpdated":"2017-06-03T18:57:20-0700","dateFinished":"2017-06-03T18:57:21-0700","dateStarted":"2017-06-03T18:57:20-0700","title":"Create Decision Tree Estimator , set Label and Feature Columns ","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndTree: org.apache.spark.ml.classification.DecisionTreeClassifier = dtc_d39b9e1e3995\n"}]}},{"text":"%md\nSet up a pipeline to pass the data through transformers to extract the features and label and pass this to a decision tree estimator to fit the model \n\n","user":"anonymous","dateUpdated":"2017-06-03T18:57:03-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Set up a pipeline to pass the data through transformers to extract the features and label and pass this to a decision tree estimator to fit the model</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1496357125187_1231242456","id":"20170601-154525_1033166149","dateCreated":"2017-06-01T15:45:25-0700","dateStarted":"2017-06-03T18:57:03-0700","dateFinished":"2017-06-03T18:57:03-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13997"},{"title":"Set up pipeline with  feature transformers and model estimator","text":"\n// put treeClassifier in a Pipeline.\n val pipeline = new Pipeline()\n      .setStages(Array(ipindexer, labelindexer, assembler, dTree))\n","user":"anonymous","dateUpdated":"2017-06-03T18:57:28-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\npipeline: org.apache.spark.ml.Pipeline = pipeline_910918fb5c1c\n"}]},"apps":[],"jobName":"paragraph_1494281757987_84799337","id":"20170508-151557_1422077156","dateCreated":"2017-05-08T15:15:57-0700","dateStarted":"2017-06-03T18:57:28-0700","dateFinished":"2017-06-03T18:57:29-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13998"},{"text":"%md\r\nSpark ML supports k-fold cross validation with a transformation/estimation pipeline to try out different combinations of parameters, using a process called grid search. You set up a CrossValidator with the parameters to test, an estimator and evaluator for a model selection workflow.\r\n","user":"anonymous","dateUpdated":"2017-06-02T15:31:21-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Spark ML supports k-fold cross validation with a transformation/estimation pipeline to try out different combinations of parameters, using a process called grid search. You set up a CrossValidator with the parameters to test, an estimator and evaluator for a model selection workflow.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1496270818601_1997387469","id":"20170531-154658_1298817002","dateCreated":"2017-05-31T15:46:58-0700","dateStarted":"2017-06-02T15:31:21-0700","dateFinished":"2017-06-02T15:31:21-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13999"},{"title":"set up a CrossValidator with the parameters to test, an estimator and evaluator for a model selection","text":"// set param grid to Search through decision tree's maxDepth parameter for best model\n val paramGrid = new ParamGridBuilder().addGrid(dTree.maxDepth, Array(2, 3, 4, 5, 6, 7)).build()\n val evaluator = new BinaryClassificationEvaluator()\n      .setLabelCol(\"label\")\n      .setRawPredictionCol(\"prediction\")\n\n// Set up 3-fold cross validation with paramGrid\n val crossval = new CrossValidator().setEstimator(pipeline)\n      .setEvaluator(evaluator)\n      .setEstimatorParamMaps(paramGrid).setNumFolds(3)","user":"anonymous","dateUpdated":"2017-06-03T19:03:44-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n\n\n\n\n\n\n\n\n\n\n\n\n\nparamGrid: Array[org.apache.spark.ml.param.ParamMap] =\nArray({\n\tdtc_d39b9e1e3995-maxDepth: 2\n}, {\n\tdtc_d39b9e1e3995-maxDepth: 3\n}, {\n\tdtc_d39b9e1e3995-maxDepth: 4\n}, {\n\tdtc_d39b9e1e3995-maxDepth: 5\n}, {\n\tdtc_d39b9e1e3995-maxDepth: 6\n}, {\n\tdtc_d39b9e1e3995-maxDepth: 7\n})\n\nevaluator: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_7a8b0a321fb9\n\ncrossval: org.apache.spark.ml.tuning.CrossValidator = cv_379d42b3d50e\n"}]},"apps":[],"jobName":"paragraph_1494281943273_68083279","id":"20170508-151903_1365343172","dateCreated":"2017-05-08T15:19:03-0700","dateStarted":"2017-06-03T19:03:44-0700","dateFinished":"2017-06-03T19:03:47-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14000"},{"title":"Fit the model to the input data using K-fold cross validation","text":"val cvModel = crossval.fit(ntrain)","user":"anonymous","dateUpdated":"2017-06-03T19:04:13-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ncvModel: org.apache.spark.ml.tuning.CrossValidatorModel = cv_379d42b3d50e\n"}]},"apps":[],"jobName":"paragraph_1494281966639_1180254432","id":"20170508-151926_10766097","dateCreated":"2017-05-08T15:19:26-0700","dateStarted":"2017-06-03T19:04:13-0700","dateFinished":"2017-06-03T19:04:43-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14001"},{"title":"Display the Best model ","text":"val bestModel = cvModel.bestModel\nprintln(\"The Best Model:\\n--------------------\")\nval treeModel = bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel].stages(3).asInstanceOf[DecisionTreeClassificationModel]\nprintln(\"Learned classification tree model:\\n\" + treeModel.toDebugString)","user":"anonymous","dateUpdated":"2017-06-03T19:04:49-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nbestModel: org.apache.spark.ml.Model[_] = pipeline_910918fb5c1c\nThe Best Model:\n--------------------\n\ntreeModel: org.apache.spark.ml.classification.DecisionTreeClassificationModel = DecisionTreeClassificationModel (uid=dtc_d39b9e1e3995) of depth 5 with 53 nodes\nLearned classification tree model:\nDecisionTreeClassificationModel (uid=dtc_d39b9e1e3995) of depth 5 with 53 nodes\n  If (feature 11 <= 3.0)\n   If (feature 3 <= 222.4)\n    If (feature 1 in {1.0})\n     If (feature 9 <= 13.1)\n      If (feature 10 <= 2.0)\n       Predict: 0.0\n      Else (feature 10 > 2.0)\n       Predict: 1.0\n     Else (feature 9 > 13.1)\n      Predict: 0.0\n    Else (feature 1 not in {1.0})\n     If (feature 4 <= 125.0)\n      If (feature 3 <= 209.5)\n       Predict: 1.0\n      Else (feature 3 > 209.5)\n       Predict: 1.0\n     Else (feature 4 > 125.0)\n      If (feature 3 <= 161.2)\n       Predict: 1.0\n      Else (feature 3 > 161.2)\n       Predict: 0.0\n   Else (feature 3 > 222.4)\n    If (feature 2 <= 0.0)\n     If (feature 5 <= 183.9)\n      If (feature 3 <= 273.3)\n       Predict: 1.0\n      Else (feature 3 > 273.3)\n       Predict: 0.0\n     Else (feature 5 > 183.9)\n      If (feature 3 <= 242.2)\n       Predict: 0.0\n      Else (feature 3 > 242.2)\n       Predict: 0.0\n    Else (feature 2 > 0.0)\n     If (feature 1 in {1.0})\n      If (feature 0 <= 57.0)\n       Predict: 1.0\n      Else (feature 0 > 57.0)\n       Predict: 0.0\n     Else (feature 1 not in {1.0})\n      If (feature 3 <= 299.5)\n       Predict: 1.0\n      Else (feature 3 > 299.5)\n       Predict: 0.0\n  Else (feature 11 > 3.0)\n   If (feature 3 <= 180.9)\n    If (feature 10 <= 0.0)\n     Predict: 1.0\n    Else (feature 10 > 0.0)\n     If (feature 5 <= 273.0)\n      If (feature 5 <= 226.1)\n       Predict: 0.0\n      Else (feature 5 > 226.1)\n       Predict: 0.0\n     Else (feature 5 > 273.0)\n      If (feature 0 <= 99.0)\n       Predict: 0.0\n      Else (feature 0 > 99.0)\n       Predict: 1.0\n   Else (feature 3 > 180.9)\n    If (feature 8 <= 104.0)\n     If (feature 8 <= 81.0)\n      If (feature 4 <= 94.0)\n       Predict: 1.0\n      Else (feature 4 > 94.0)\n       Predict: 0.0\n     Else (feature 8 > 81.0)\n      If (feature 4 <= 137.0)\n       Predict: 1.0\n      Else (feature 4 > 137.0)\n       Predict: 0.0\n    Else (feature 8 > 104.0)\n     If (feature 0 <= 135.0)\n      Predict: 0.0\n     Else (feature 0 > 135.0)\n      If (feature 0 <= 160.0)\n       Predict: 1.0\n      Else (feature 0 > 160.0)\n       Predict: 0.0\n\n"}]},"apps":[],"jobName":"paragraph_1494281987038_-922367659","id":"20170508-151947_197896730","dateCreated":"2017-05-08T15:19:47-0700","dateStarted":"2017-06-03T19:04:49-0700","dateFinished":"2017-06-03T19:04:53-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14002"},{"title":"fields Customer service calls and Total day minutes have high predictive power to determine a customer's likeliness to churn","text":"////0-11 feature columns: len, iplanIndex, numvmail, tdmins, tdcalls, temins, tecalls, tnmins, tncalls, timins, ticalls, numcs\rprintln( \"Feature 11:\" +  featureCols(11) +  \" Feature 3:\" +  featureCols(3))\r","user":"anonymous","dateUpdated":"2017-05-24T23:18:39-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Feature 11:numcs Feature 3:tdmins\n"}]},"apps":[],"jobName":"paragraph_1495692746976_-2136564925","id":"20170524-231226_52953518","dateCreated":"2017-05-24T23:12:26-0700","dateStarted":"2017-05-24T23:18:39-0700","dateFinished":"2017-05-24T23:18:40-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14003"},{"text":"%md\r\nThe actual performance of the model can be determined using the test data set which has not been used for any training or cross-validation activities. We'll transform the test set with the model pipeline, which will map the features according to the same recipe. \r\n","user":"anonymous","dateUpdated":"2017-06-02T15:53:45-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>The actual performance of the model can be determined using the test data set which has not been used for any training or cross-validation activities. We&rsquo;ll transform the test set with the model pipeline, which will map the features according to the same recipe.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1496443997313_309199915","id":"20170602-155317_1487132664","dateCreated":"2017-06-02T15:53:17-0700","dateStarted":"2017-06-02T15:53:45-0700","dateFinished":"2017-06-02T15:53:45-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14004"},{"title":"Get Predictions from Test set and Evaluate","text":"//transform the test set with the model pipeline, which will map the features according to the same recipe\nval predictions = cvModel.transform(test)\n","user":"anonymous","dateUpdated":"2017-06-03T19:06:02-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\npredictions: org.apache.spark.sql.DataFrame = [state: string, len: int ... 24 more fields]\n"}]},"apps":[],"jobName":"paragraph_1494284328218_588666033","id":"20170508-155848_1997894070","dateCreated":"2017-05-08T15:58:48-0700","dateStarted":"2017-06-03T19:06:02-0700","dateFinished":"2017-06-03T19:06:03-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14005"},{"text":"predictions.select(\"label\",\"prediction\", \"probability\").show","user":"anonymous","dateUpdated":"2017-06-02T16:03:26-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+----------+--------------------+\n|label|prediction|         probability|\n+-----+----------+--------------------+\n|  1.0|       1.0|[0.10676156583629...|\n|  0.0|       0.0|[0.91666666666666...|\n|  0.0|       0.0|           [1.0,0.0]|\n|  1.0|       1.0|[0.10676156583629...|\n|  1.0|       1.0|[0.10676156583629...|\n|  1.0|       1.0|           [0.1,0.9]|\n|  1.0|       1.0|[0.27027027027027...|\n|  0.0|       0.0|[0.91666666666666...|\n|  1.0|       1.0|[0.10676156583629...|\n|  1.0|       1.0|[0.10676156583629...|\n|  1.0|       1.0|[0.10676156583629...|\n|  1.0|       1.0|[0.48275862068965...|\n|  1.0|       1.0|[0.27027027027027...|\n|  1.0|       1.0|[0.10676156583629...|\n|  0.0|       1.0|[0.10676156583629...|\n|  1.0|       1.0|[0.10676156583629...|\n|  0.0|       0.0|[0.95192307692307...|\n|  1.0|       0.0|[0.57142857142857...|\n|  1.0|       1.0|[0.10676156583629...|\n|  1.0|       1.0|         [0.08,0.92]|\n+-----+----------+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1496444542248_54846955","id":"20170602-160222_471240064","dateCreated":"2017-06-02T16:02:22-0700","dateStarted":"2017-06-02T16:03:26-0700","dateFinished":"2017-06-02T16:03:28-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14006"},{"text":"%md\nAccuracy is measured by the area under the ROC curve. \nThe area measures the ability of the test to correctly classify true positives from false positives.\n●\tTrue positives are how often the model correctly predicted churn (subscription canceling)\n●\tFalse positives are how often the model incorrectly predicted churn (subscription canceling)\nIn this case, the evaluation returns 84.8% precision. ","user":"anonymous","dateUpdated":"2017-06-02T16:23:22-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Accuracy is measured by the area under the ROC curve.<br/>The area measures the ability of the test to correctly classify true positives from false positives.<br/>● True positives are how often the model correctly predicted churn (subscription canceling)<br/>● False positives are how often the model incorrectly predicted churn (subscription canceling)<br/>In this case, the evaluation returns 84.8% precision.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1496445338244_1925657572","id":"20170602-161538_1648758337","dateCreated":"2017-06-02T16:15:38-0700","dateStarted":"2017-06-02T16:23:22-0700","dateFinished":"2017-06-02T16:23:22-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14007"},{"text":"//The evaluator will provide us with the score of the predictions by comparing the prediction to the label\nval accuracy = evaluator.evaluate(predictions)\nevaluator.explainParams()","user":"anonymous","dateUpdated":"2017-06-03T19:07:04-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\naccuracy: Double = 0.8484817813765183\n\n\n\n\nres86: String =\nlabelCol: label column name (default: label, current: label)\nmetricName: metric name in evaluation (areaUnderROC|areaUnderPR) (default: areaUnderROC)\nrawPredictionCol: raw prediction (a.k.a. confidence) column name (default: rawPrediction, current: prediction)\n"}]},"apps":[],"jobName":"paragraph_1496444182216_-2145853812","id":"20170602-155622_1453197792","dateCreated":"2017-06-02T15:56:22-0700","dateStarted":"2017-06-03T19:07:04-0700","dateFinished":"2017-06-03T19:07:06-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14008"},{"title":"Calculate some more metrics","text":"val predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd.map(x =>\n      (x(0).asInstanceOf[Double], x(1).asInstanceOf[Double]))\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)\nprintln(\"area under the precision-recall curve: \" + metrics.areaUnderPR)\nprintln(\"area under the receiver operating characteristic (ROC) curve : \" + metrics.areaUnderROC)\nprintln(metrics.fMeasureByThreshold())","user":"anonymous","dateUpdated":"2017-06-02T16:04:41-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\npredictionAndLabels: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[1255] at map at <console>:140\n\nmetrics: org.apache.spark.mllib.evaluation.BinaryClassificationMetrics = org.apache.spark.mllib.evaluation.BinaryClassificationMetrics@2aba93f2\narea under the precision-recall curve: 0.9747578698231796\narea under the receiver operating characteristic (ROC) curve : 0.8484817813765183\nMapPartitionsRDD[1273] at map at BinaryClassificationMetrics.scala:214\n"}]},"apps":[],"jobName":"paragraph_1494284356519_-480889937","id":"20170508-155916_542263952","dateCreated":"2017-05-08T15:59:16-0700","dateStarted":"2017-06-02T16:04:41-0700","dateFinished":"2017-06-02T16:04:46-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14009"},{"title":"More metrics","text":"\nval lp = predictions.select(\"label\", \"prediction\")\nval counttotal = predictions.count()\nval correct = lp.filter($\"label\" === $\"prediction\").count()\nval wrong = lp.filter(not($\"label\" === $\"prediction\")).count()\nval ratioWrong = wrong.toDouble / counttotal.toDouble\nval ratioCorrect = correct.toDouble / counttotal.toDouble\nval truep = lp.filter($\"prediction\" === 0.0).filter($\"label\" === $\"prediction\").count() / counttotal.toDouble\nval truen = lp.filter($\"prediction\" === 1.0).filter($\"label\" === $\"prediction\").count() / counttotal.toDouble\nval falsep = lp.filter($\"prediction\" === 1.0).filter(not($\"label\" === $\"prediction\")).count() / counttotal.toDouble\nval falsen = lp.filter($\"prediction\" === 0.0).filter(not($\"label\" === $\"prediction\")).count() / counttotal.toDouble\nprintln(\"counttotal : \" + counttotal)\nprintln(\"correct : \" + correct)\nprintln(\"wrong: \" + wrong)\nprintln(\"ratio wrong: \" + ratioWrong)\nprintln(\"ratio correct: \" + ratioCorrect)\nprintln(\"ratio true positive : \" + truep)\nprintln(\"ratio false positive : \" + falsep)\nprintln(\"ratio true negative : \" + truen)\nprintln(\"ratio false negative : \" + falsen)\nprintln(\"wrong: \" + wrong)\n\nval equalp = predictions.selectExpr(\n      \"double(round(prediction)) as prediction\", \"label\",\n      \"\"\"CASE double(round(prediction)) = label WHEN true then 1 ELSE 0 END as equal\"\"\"\n    )\nequalp.show","user":"anonymous","dateUpdated":"2017-06-03T19:08:11-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nlp: org.apache.spark.sql.DataFrame = [label: double, prediction: double]\n\ncounttotal: Long = 667\n\ncorrect: Long = 574\n\nwrong: Long = 93\n\nratioWrong: Double = 0.13943028485757122\n\nratioCorrect: Double = 0.8605697151424287\n\ntruep: Double = 0.1184407796101949\n\ntruen: Double = 0.7421289355322339\n\nfalsep: Double = 0.0239880059970015\n\nfalsen: Double = 0.11544227886056972\ncounttotal : 667\ncorrect : 574\nwrong: 93\nratio wrong: 0.13943028485757122\nratio correct: 0.8605697151424287\nratio true positive : 0.1184407796101949\nratio false positive : 0.0239880059970015\nratio true negative : 0.7421289355322339\nratio false negative : 0.11544227886056972\nwrong: 93\n\nequalp: org.apache.spark.sql.DataFrame = [prediction: double, label: double ... 1 more field]\n+----------+-----+-----+\n|prediction|label|equal|\n+----------+-----+-----+\n|       1.0|  1.0|    1|\n|       0.0|  0.0|    1|\n|       0.0|  0.0|    1|\n|       1.0|  1.0|    1|\n|       1.0|  1.0|    1|\n|       1.0|  1.0|    1|\n|       1.0|  1.0|    1|\n|       0.0|  0.0|    1|\n|       1.0|  1.0|    1|\n|       1.0|  1.0|    1|\n|       1.0|  1.0|    1|\n|       1.0|  1.0|    1|\n|       1.0|  1.0|    1|\n|       1.0|  1.0|    1|\n|       1.0|  0.0|    0|\n|       1.0|  1.0|    1|\n|       0.0|  0.0|    1|\n|       0.0|  1.0|    0|\n|       1.0|  1.0|    1|\n|       1.0|  1.0|    1|\n+----------+-----+-----+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1494284375085_1134902202","id":"20170508-155935_1678385472","dateCreated":"2017-05-08T15:59:35-0700","dateStarted":"2017-06-03T19:08:11-0700","dateFinished":"2017-06-03T19:08:35-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14010"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1494284407931_1396192678","id":"20170508-160007_1145560554","dateCreated":"2017-05-08T16:00:07-0700","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:14011"}],"name":"/spark test","id":"2CFPBN6RK","angularObjects":{"2CHXR4W7F:shared_process":[],"2CG6DXK9D:shared_process":[],"2CHH1ACAC:shared_process":[],"2CF1TTFEJ:shared_process":[],"2CHDCCPCB:shared_process":[],"2CFEZNG6F:shared_process":[],"2CESGQKN8:shared_process":[],"2CGFE6AB5:shared_process":[],"2CFJ35H8N:shared_process":[],"2CFZT44X4:shared_process":[],"2CH5RZKHJ:shared_process":[],"2CEX6K3ZQ:shared_process":[],"2CGKBWFY7:shared_process":[],"2CJ888C6R:shared_process":[],"2CEUCFBEM:shared_process":[],"2CGZAMKG3:shared_process":[],"2CJANSWCG:shared_process":[],"2CGNBN97X:shared_process":[],"2CF8ATGYV:shared_process":[]},"config":{"looknfeel":"simple","personalizedMode":"false"},"info":{}}